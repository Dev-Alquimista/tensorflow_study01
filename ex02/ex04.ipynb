{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ex04.ipynb","provenance":[],"authorship_tag":"ABX9TyNgi3IZhBIMhjPGUeB5HUXY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"id":"7OdG-UeEUaQr","executionInfo":{"status":"ok","timestamp":1655195946587,"user_tz":-540,"elapsed":511,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"outputs":[],"source":["import cv2 \n","import os  \n","import sys \n","import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","import tensorflow as tf "]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential,Model, load_model \n","from tensorflow.keras.layers import Activation, Dense, Input, Dropout, Flatten \n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop \n","from tensorflow.keras.datasets import mnist "],"metadata":{"id":"_pZy0CZSUnIS","executionInfo":{"status":"ok","timestamp":1655195947022,"user_tz":-540,"elapsed":12,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def get_show_shape(images):\n","    for i in range(len(images)):\n","        print(f\"shape {images[i].shape}\")\n","\n","def get_show_images(images, labels, ncols=15):\n","    fig, axes = plt.subplots(3, 5)\n","    fig.set_size_inches(8, 5)\n","    for i in range(ncols):\n","        ax = axes[i//5, i%5]\n","        ax.imshow(images[i], cmap=\"gray\")\n","        ax.axis(\"off\")\n","        ax.set_title(str(labels[i]))\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"96UhSB_6Vok7","executionInfo":{"status":"ok","timestamp":1655195947023,"user_tz":-540,"elapsed":12,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def get_preprocessed_scaler(x_train, x_test):\n","    x_train = x_train / x_train.max()\n","    x_test = x_test / x_test.max()\n","\n","    return x_train, x_test "],"metadata":{"id":"Rvms8FkQW4cd","executionInfo":{"status":"ok","timestamp":1655195947024,"user_tz":-540,"elapsed":12,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","# get_show_shape([x_train, y_train, x_test, y_test])\n","# get_show_images(x_train[0:15], y_train[0:15], ncols=15)"],"metadata":{"id":"86_7hLAOVU4d","executionInfo":{"status":"ok","timestamp":1655196406627,"user_tz":-540,"elapsed":880,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["x_train = x_train / x_train.max()\n","x_test = x_test / x_test.max()"],"metadata":{"id":"4vQPmOcfZLQA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### layer initializer  \n","- 초기화 함수는 keras layer의 parameter의 초기값을 어떤 방식을 생성할지 결정한다. \n","- 모든 층에서 다 똑같지는 않지만 대부분의 경우 kernel_initializer와 bias_initializer 인자를 사용해서 weight와 bias 초기화 함수를 지정한다.\n","- keras.initializers.Initializer() 클래스를 상속받는다. "],"metadata":{"id":"5-L3zHxUZO5z"}},{"cell_type":"code","source":["dense = Dense(256, activation=\"relu\")\n","dense.get_config()[\"kernel_initializer\"]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0PC-BmkbToi","executionInfo":{"status":"ok","timestamp":1655197000286,"user_tz":-540,"elapsed":8,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"00eacbb9-4817-41e6-c6cc-4cc43309fea6"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'class_name': 'GlorotUniform', 'config': {'seed': None}}"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["dense = Dense(256, kernel_initializer=\"he_normal\", activation=\"relu\")\n","print(dense.get_config()[\"kernel_initializer\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVdT33oybhuB","executionInfo":{"status":"ok","timestamp":1655197057331,"user_tz":-540,"elapsed":360,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"ba5a4871-4372-4302-d388-912b71a3e0f9"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["{'class_name': 'HeNormal', 'config': {'seed': None}}\n"]}]},{"cell_type":"markdown","source":["#### Regularization\n","- 모델의 과대적합을 해소하기 위해서 L1, L2 규제를 적용하기도 한다. \n","- keras layer는 기본값으로 규제를 적용하고 있지 않다. 따라서 규제를 적용할 경우에는 별도로 설정이 필요하다. \n","- keras layer의 규제를 적용하기 위해서는 kernel_regularizer에 규제를 지정한다.  "],"metadata":{"id":"6hzp_K24bvJf"}},{"cell_type":"code","source":["dense = Dense(256, kernel_regularizer=\"l1\", activation=\"relu\")\n","dense.get_config()[\"kernel_regularizer\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6bw_cG4cQwr","executionInfo":{"status":"ok","timestamp":1655197251464,"user_tz":-540,"elapsed":508,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"aad93b61-d982-4522-a74d-2bcc46390800"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'class_name': 'L1', 'config': {'l1': 0.009999999776482582}}"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["#### Dropout \n","- 딥러닝 모델의 층이 넓고 깊어질 때 모델은 훈련에 주어진 샘플에 과하게 적합하도록 학습하는 경향이 있다. \n","- 훈련데이터셋에 너무 적응하여 검증 데이터셋이나 테스트데이터셋에 일반화된 성능을 갖지 못하는문제가 발생하기 때문에 Dropout는 과대적합 문제를 해결하기 위해서 제안된 것이다. \n","- Dropout에 입력되는 숫자는 노드에서 제거되는 비율을 나타낸다.  "],"metadata":{"id":"3r3NVFy8cggq"}},{"cell_type":"code","source":["Dropout(0.25)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljAfQLt_fZot","executionInfo":{"status":"ok","timestamp":1655198047003,"user_tz":-540,"elapsed":347,"user":{"displayName":"BYEONGDU JEONG","userId":"08814862544435438676"}},"outputId":"504f84ab-0b65-4400-8a3d-92e77b7fc07b"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.layers.core.dropout.Dropout at 0x7fe4b0144b50>"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["#### BatchNormalization\n","* BatchNormalization는 각 층에서 활성화 함수를 통과하기 전에 mini-bacth의 스케일을 정규화한다. \n","* 다음층으로 데이터가 전달되기 전에 스케일을 조정하기 때문에 보다 안정적인 훈련이 가능하고, 성능이 향상된다. \n","  "],"metadata":{"id":"MwZGGdH5eZ8I"}}]}